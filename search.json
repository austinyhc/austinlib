[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am Austin; A System Software Engineer by passion. Data Science Practitioner at heart. Avid reader. Essentialist. Nerd. Newbie Rustacean. Virgo. ♍"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Pragmas\n\n\n\n\n\n\n\nbyte-wise\n\n\n\n\n\n\n\n\n\n\n\nMar 16, 2023\n\n\nAustin Chen\n\n\n\n\n\n\n  \n\n\n\n\nData Alignment\n\n\n\n\n\n\n\nbyte-wise\n\n\nc\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nAustin Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/bytewise-pragmas/index.html#option-stacking",
    "href": "posts/bytewise-pragmas/index.html#option-stacking",
    "title": "Pragmas",
    "section": "Option stacking",
    "text": "Option stacking\nIt is important to note, that a pragma directive applies for the whole file from file from that point. Everything before it is unaffected. This is why, when applying certain options just for a small section, it is useful to save current options and restore them back afte the said section.\nThis is why you should use push and pop options before and after applying a progma. Push and pop can be used as a value to an option or as part of the option as well. Here are a few examples\n#pragma GCC diagnostic push\n#pragma GCC diagnostic error \"-Wformat\" // treat this warning as error\n\n// section affected by\nvoid foo()\n{\n    ...\n}\n\n#pragma GCC diagnostic pop\n#define MACRO 1\n#pragma GCC push_macro(\"MACRO\") // save MACRO value to stack\n#undef MACRO // undefine macro MACRO\n\n// section affected by\nvoid foo()\n{\n    ...\n}\n\n#pragma GCC pop_macro(\"MACRO\") // pop value of macro MACRO back\n## Code optimization\nFor most scenarios, I stand by a rule to use the same optimization options for both Debug and Release builds. This prevents unnessary errors and code breakage when switching builds types, where optimizer might do a too-good job and it ends up breaking the executaable. Remember, build type is not just about optimization level.\nFor my builds, I use option Og for gcc compiler. This is, by my estimations, the est compromise between optimized code and debug-ability. However it still isn’t perfect. While it does prevent inlining of regular functions, some lambdas and trivial class methods do get inlined. Sometimes whole if-else blocks get optimized to a point, that you cannot put a breakpoint anywhere useful. Even if you do, some variables might get optimized and debugger will not be able to give you any information on their value.\n#pragma GCC push_options // save current compiler options\n#pragma GCC optimize (\"-O0\") // set optimization level to zero\n\nvoid foo(int a)\n{\n    int cpy = a;\n    return cpy + 5;\n}\n\n#pragma GCC pop_options // restore saved compiler options\nIn the example above, such trivial function might get optimized away. If not, stepping through it might prove useless, as variable cpy might get optimized so that debugger cannot see its value. Setting optimization level to zero disables any funny business from the compiler and forces it to generate expected instructions."
  },
  {
    "objectID": "posts/bytewise-data-alignment/index.html#memory-addressing",
    "href": "posts/bytewise-data-alignment/index.html#memory-addressing",
    "title": "Data Alignment",
    "section": "Memory addressing",
    "text": "Memory addressing\nComputers commonly address the memory in word-sized chucks. A word is a computer’s natural unit for data. Its size is defined by the computers architecture. Modern general purpose computers generally have a word-size of either 32-bit or 64-bit. To find out the natural word-size of a processor running a modern UNIX, one can issue the following commands:\ngetconf WORD_BIT\ngetconf LONG_BIT\nIn the case of a modern x86_64 computer, WORD_BIT would return 32 and LONG_BIT would return 64.\n\nAlignment\n\nC11 Stadndard § 3.1 alignment\nrequirement that objects of a particular type be located on storage boundaries with addresses that are particular multiples of a byte address\n\nComputer memory alignment has always been a very important aspect of computing. As we’ve already learned, old computers were unable to address improperly aligned data and more recent computers will experience a severe slowdown doing so. Only the most recent computers available can load misaligned data as well as aligned data1.\nFor instance, saving a 4 byte int in our memory will result in the intger being properly aligned without doing any extra work because an int on this architecture is exactly 4 byte which will fit perfectly into the first slot. \nIf we instead decided to put a char and an int into our memory we would get a problem if we did so naively without worrying for alignement.\nThis would need two memory accesses and some bitshifting to fetch the int. Effectively that means it will take at least two times as long as it would if the data were properly aligned. For this reason, computer scientists came up with the idea of adding padding to data in memory so it would be properly aligned.\n\n\n\nConsequence of misalignment\nThe consequence of data structure misalignment vary widely between architectures. Some RISC, ARM and MIPS processors will respond with an alignment fault if an attempt is made to access a misaligned address. Specialized processors such DSPs usually don’t support accessing misaligned locations. Most modern general purpose processors are capable of accessing misaligned addresses, albeit at a steep performance hit of at least two times the aligned access time. Very modern X86_64 processors are capable of handling misaligned accesses without a performance hit. SSE requires data structures to be aligned per specification and would result in undefined behavior if attempted to be used with unaligned data."
  },
  {
    "objectID": "posts/bytewise-data-alignment/index.html#in-practice",
    "href": "posts/bytewise-data-alignment/index.html#in-practice",
    "title": "Data Alignment",
    "section": "In Practice",
    "text": "In Practice\nThis chapter will introduce the alignment of struct in C. It will use a series of exmaples to do so.\n\nExample with struct\nstruct Test {\n    char x;   // 1 byte\n    double y; // 8 bytes\n    char z;   // 1 bytes\n};\nIntuitively, this Test structure takes 1 byte + 8 bytes + 1 byte = 10 bytes, while the fact is 24 bytes.\n\n:pencil2: A struct is always aligned to the largest type’s alignment requirements\n\nstruct Test {\n    char x;   // 1 byte\n    char z;   // 1 bytes\n    double y; // 8 bytes\n};\nNow it’s only 16 bytes which is the best we can do if we want to keep our memory naturally aligned.\nwarning: padding struct to align ‘a’ [-Wpadded]\n   23 |     int a;\n\n\nPadding in the real world\nThe previous chapters might lead you to believe that a lot of manual care has to be taken about data structures in C. In reality, however, it should be noted that just about every modern compiler will automatically use data structure padding depending on architecture. Some compilers even support the warning flag -Wpadded which generates helpful warnings about structure padding. These warnings help the programmer take manual care in case a more efficient data structure layout is desired.\nIf desired, it’s actually possible to prevent the compiler from padding a struct using either __attribute((packed)) after a struct definition, #pragma pack(1) in front of a struct definition or -fpack-struct as a compiler parameter.\n\n\nExperiemnt\nLet us compare the diff of the following code.\n--struct Test1 {\n++struct Test2 {\n    char x;   // 1 byte\n    double y; // 8 bytes\n    char z;   // 1 bytes\n--}\n++} __attribute__((packed));\nint main()\n{\n    struct timespec start, end;\n--    struct Test1 test;\n++    struct Test2 test;\n\n    clock_gettime(CLOCK, &start);\n    for (unsigned long i = 0; i &lt; RUNS; ++i) {\n        test.y = 1;\n        test.y += 1;\n    }\n    clock_gettime(CLOCK, &end);\n\n    struct timespec delta = diff(start, end);\n\n    printf(\"%ld\\n\", delta.tv_nsec);\n}\n\nThe benchmark was compiled with gcc using\n\ngcc -DRUNS=400000000 -DCLOCK=CLOCK_MONOTONIC -O0 -o test.out\n\nand run by the script\n\nprintf \"time,elapsed\\n\" &gt; result.txt\nfor i in {1..200}; do echo 3 &gt; /proc/sys/vm/drop_caches; printf \"%d, \" $i; ./test.out; done &gt;&gt; result.txt\n\nand eventually use the following Python script to plot the final comparison result as we shown at the beginning of this article\n\nimport click\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\ndef hello():\n    cwd = Path.cwd()\n    df1 = pd.read_csv(cwd/'result1.txt')\n    df2 = pd.read_csv(cwd/'result2.txt')\n    ax = df1.elapsed.plot.line()\n    ax = df2.elapsed.plot.line(ax=ax)\n    ax.legend(['unaligned', 'aligned'])\n    plt.show()\n\nif __name__ == '__main__':\n    hello()"
  },
  {
    "objectID": "posts/bytewise-data-alignment/index.html#footnotes",
    "href": "posts/bytewise-data-alignment/index.html#footnotes",
    "title": "Data Alignment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAgner’s CPU blog, “Test results for Intel’s Sandy Bridge processor”, https://www.agner.org/optimize/blog/read.php?i=142&v=t↩︎"
  }
]